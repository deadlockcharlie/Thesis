% !TEX root = ../main.tex
%



\chapter{Introduction} \label{chap:intro}
\adjustmtc

Databases are critical components in the infrastructure of modern organizations, serving as systems for the efficient storage, management and retrieval of vast amounts of data. As businesses and institutions increasingly pivot toward data-driven strategies, databases become paramount, enabling organizations to leverage data for informed decision-making and operational efficiency. The importance of databases extends across various sectors, from retail and finance to healthcare and scientific research, illustrating their versatility.


Consistency in databases is crucial for ensuring the accuracy and reliability of stored data, particularly in environments with concurrent access. It guarantees the database adheres to a defined set of rules and constraints. Without consistency, errors such as data corruption, conflicting updates, or invalid relationships between data entities can undermine the system's integrity. This is vital as consistent data forms the foundation for meaningful analytics, reliable application behaviour, and user trust.

In databases, managing data consistency during concurrent access is a foundational challenge. It can be specified through constraints or invariants, which are conditions on data. A database is in a consistent state when all specified invariants are satisfied. These constraints can be classified into two main types: \textbf{Physical} and \textbf{Logical}. Physical constraints typically govern relationships within the database. For example, \emph{if record A refers to record B, then record B must exist for the database to remain consistent}. Logical constraints, on the other hand, involve higher-level properties of the data, such as \emph{the sum of money across all accounts in a financial system remains constant}. These constraints collectively ensure that the database behaves predictably and correctly, even under concurrent access.

The ACID (Atomicity, Consistency, Isolation, Durability) model is a set of properties that ensure data validity. Under this model, a transaction is a series of accesses to the database involving reads and writes to specific data items. It is delimited by a \emph{begin} operation that marks the start of the transaction and a \emph{commit} operation that applies all the changes atomically. By grouping multiple accesses into a single unit of work, transactions provide a means to apply updates to the database as an indivisible operation. When applied to an initially consistent database, a correct transaction must leave it consistent when it commits. This property ensures that the invariants hold before and after every transaction.

However, this notion of correctness is primarily concerned with the final state of the database, and it does not enforce consistency during the execution of a transaction. In practice, applications that interact with a database often assume that transactions will always observe a consistent database state. This expectation goes beyond the pre-application and post-application consistency invariants. To meet this expectation, transactions must be atomic and \textbf{isolated}. Isolation ensures that a transaction can execute as though it were the only transaction interacting with the database at that time. Without isolation, a transaction could read or write data in a temporarily inconsistent state, leading to incorrect or unpredictable outcomes. Locks are one of the mechanisms used to enforce isolation. By preventing simultaneous access to the same data by multiple transactions, locks ensure that no transaction observes an intermediate, inconsistent state created by another transaction.

Modern database systems have evolved to handle increasingly complex data models, such as hierarchical structures. Hierarchical data models are widely used in domains where relationships between data elements must be explicitly represented and managed. Examples include \textbf{File systems}, where directories and files form a hierarchy; \textbf{Organizational structures}, where departments and employees are arranged in levels; \textbf{Ontologies}, where concepts are related in a taxonomic order; \textbf{XML databases}, where data is structured in a tree-like format; and more recently, \textbf{Document stores}, where data is stored as nested objects that contain key-value pairs. These hierarchical models naturally capture relationships across different levels of abstraction, and they often involve multiple users or processes accessing the data concurrently. Typically, vertices represent data elements in these models, while edges capture their relationships or connections.

In such hierarchical models, transactions access data by acquiring locks on the vertices that contain the required data. To maintain atomicity and isolation, a transaction that needs to access multiple data items may require multiple locks, often at different levels of the hierarchy. This poses challenges because the hierarchy's topology and the transactions' access patterns are not constrained. Multi-granularity locking (MGL) is a well-established mechanism for addressing these challenges. MGL allows locks to be managed at varying levels of granularity, enabling \emph{coarse-grain} locks at higher levels of the hierarchy and \emph{fine-grain} locks at lower levels. This flexibility is critical for supporting efficient concurrency control. For example, a transaction that requires broad access to a large portion of the data can acquire a coarse-grain lock at a higher level. In contrast, another transaction that needs access to specific items can acquire fine-grain locks at lower levels. This approach minimizes contention and maximizes parallelism.

However, implementing MGL effectively in systems with hierarchical and highly interconnected data introduces unique challenges. Hierarchical data structures often have complex topologies with relationships that span multiple levels. Efficiently managing locks in such environments requires careful consideration of both the hierarchy structure and the access patterns of concurrent transactions. Tailoring MGL to these scenarios is essential for achieving scalable and efficient concurrency control. By adapting MGL to hierarchical data models, it is possible to support a higher degree of parallelism while maintaining the consistency of the database. This research explores these adaptations, focusing on techniques that allow MGL to operate effectively in environments characterized by complex data relationships and diverse transaction workloads. These adaptations aim to achieve scalable, high-performance concurrency control that ensures consistency in even the most demanding hierarchical database systems.

\section*{Problem statement}

While multi-granularity locking (MGL) is widely applied in simple hierarchical data models, adapting it to handle complex, irregular, and deeply nested hierarchies remains a significant challenge. Scalability becomes a pressing issue as hierarchies grow more extensive and more intricate. This is particularly true in scenarios where the size and depth of the hierarchy expand significantly or where the relationships between elements deviate from strict hierarchical patterns, approaching those of graph-like data models. These complexities introduce obstacles that make straightforward adaptations of traditional MGL frameworks insufficient.

One of the core challenges lies in efficiently determining a \textbf{lockable unit} within these intricate structures. A lockable unit represents a portion of the hierarchy a transaction can safely operate in isolation without causing conflicts with other concurrent transactions. This task is often straightforward in hierarchies with simple topologies, like trees, because the structure guides lock placement. However, identifying appropriate lockable units becomes increasingly tricky in hierarchies characterized by significant depth and irregularity. This process must account for the complexity of the hierarchy's topology, which is dynamic and evolves as transactions update data. As a result, determining lockable units in such scenarios can become computationally intensive, requiring careful consideration of the hierarchy's structure to maintain efficiency.

Once locks are established, managing and resolving their conflicts poses another substantial challenge. In simple hierarchical data models, conflicts are often limited to well-defined scenarios, such as two transactions attempting to access the same vertex or its immediate descendants. However, in more complex hierarchies, transactions may interact with multiple levels of the hierarchy simultaneously, creating more intricate conflict scenarios. The structure's irregularity and depth further complicate conflict detection and resolution, as transactions may inadvertently interact with distant or seemingly unrelated parts of the hierarchy. This increases the complexity of ensuring that transactions proceed without violating isolation.


To address these issues, it is necessary to extend existing MGL frameworks to better accommodate complex dynamic hierarchical data. Such extensions must focus on two critical aspects: \textbf{lock placement} and \textbf{conflict management}. Lock placement must be tailored to the unique characteristics of intricate hierarchies, ensuring that lockable units are defined to balance fine-grained control with the need to minimize overhead. Conflict management must scale effectively with the complexity of the hierarchy and the level of parallelism, providing mechanisms to detect and resolve conflicts promptly and efficiently. These enhancements must be designed to ensure that the fundamental goals of MGL—scalability, high performance, and data consistency—are upheld, even in environments with irregular and deeply nested structures.

Extending MGL to meet these requirements makes it possible to support concurrency control in even the most challenging hierarchical models. These adaptations aim to preserve the key benefits of MGL while addressing the unique demands posed by environments characterized by structural irregularity, increased depth, and distributed operation.



\section*{Contributions}

In this work, we present CALock, a novel MGL protocol specifically designed to address the challenges of concurrency control in complex dynamic hierarchical data models. CALock extends the traditional MGL framework to support hierarchies with arbitrary depth, structural complexity and dynamic topology, enabling efficient and scalable concurrency management across diverse application domains. By adapting MGL principles to account for the intricacies of highly interconnected, dynamic hierarchical data, CALock ensures high performance and data consistency, even under challenging workloads.

MGL techniques establish a granularity at which a transaction acquires a lock, optimizing access based on the specific needs of the transaction. CALock innovates in this area by employing a partial ordering of the vertices in the hierarchy to determine lock granularity dynamically. This ordering is defined through a vertex labelling scheme, where each vertex is assigned a label that represents a set of its common ancestors. These labels are computed recursively using a breadth-first traversal over the hierarchy, efficiently capturing the topology. At runtime, vertex labels provide a means to identify an appropriate lock granularity for a lock request, tailoring the locking strategy to the transaction's specific access pattern. As a hierarchy evolves, CALock adapts the lock granularity by efficiently updating vertex labels, ensuring that locks remain effective even as the hierarchy structure changes.

One of the core principles of CALock is to minimize the granularity of locks wherever possible. By doing so, CALock ensures that each lock covers only the smallest necessary portion of the hierarchy, thereby improving the level of parallelism available to concurrent transactions. An additional benefit of CALock is its ability to eliminate the need for fixed vertex ordering, a common requirement in many other MGL techniques. This design choice avoids the overhead associated with frequent relabeling of vertices as the hierarchy evolves, reducing computational costs while maintaining the same level of correctness and isolation guarantees as other MGL protocols.

CALock offers a robust solution for concurrency control in complex, irregular hierarchies through its novel approach to lock granularity and adaptive labelling mechanism. These features make it well-suited for environments requiring high scalability and dynamic adaptability.

\newpage
\section*{Publications}

The work presented in this thesis has been successively presented in the following publications:



\begin{enumerate}
    \item A. Pandey, J. Sopena, M. Shapiro, and S. Dubois, "CALock: Multi-granularity locking in dynamic hierarchies," in 2024 IEEE International Parallel and Distributed Processing Symposium (IPDPS), Milan, Italy, June 2025.
    \item A. Pandey, J. Sopena, and M. Shapiro, "Diversifying locks for effective synchronization in dynamic graphs," in EuroSys 2024 Doctoral Workshop, Athens, Greece, April 2024 \href{https://inria.hal.science/hal-04851918}{\color{blue}{\underline{Online}}}.
    \item A. Pandey, S. Dubois, M. Shapiro, and J. Sopena, "CALock: Multi-Granularity Locking in Directed Graphs," in ComPas 2023, Annecy, France, July 2023. \href{https://hal.sorbonne-universite.fr/hal-04851841}{\color{blue}{\underline{Online}}}. 
\end{enumerate}

\section*{Thesis structure}
The remainder of this thesis is organized as follows:

 \cref{chap:background} presents an overview of concurrency control, multi-granularity locking and the challenges associated with complex hierarchical data models. 

 \cref{chap:relatedwork} reviews existing research in multi-granularity locking, highlighting the limitations of current techniques. 

 \cref{chap:CALock} provides a theoretical framework for CALock, which includes the concept of the lowest common ancestors in graphs and the problem formulation for lock grain selection. It introduces CALock, our novel multi-granularity locking protocol, and describes its design and implementation. We also discuss the properties of CALock, such as safety, liveness, and fairness and present the complexity analysis of CALock to compare it with state-of-the-art techniques.

 \cref{chap:implementation} describes the implementation of CALock, including the design choices and optimizations made to improve performance. We present an experimental evaluation of CALock, comparing its performance against state-of-the-art techniques in various scenarios using both micro-benchmarks and macro-benchmarks.
 
 Finally, \cref{chap:conclusion} concludes the thesis, summarizing our contributions and outlining future research directions in multi-granularity locking for complex hierarchical data models.
